---
title: "调优案例"
date: 2023-05-08T20:30:30+08:00
lastmod: 2023-05-08T20:30:30+08:00
author: ["AlfredNing"]
keywords: 
- 
categories: # 没有分类界面可以不填写
- 
tags: # 标签
- jvm
description: ""
weight:
slug: ""
draft: false # 是否为草稿
comments: true # 本页面是否显示评论
reward: true # 打赏
mermaid: true #是否开启mermaid
showToc: true # 显示目录
TocOpen: true # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示路径
cover:
    image: "" #图片路径例如：posts/tech/123/123.png
    caption: "" #图片底部描述
    alt: ""
    relative: false
---

# 调优工具

- jConsole
- Visual VM
- eclipse MAT
- JProfiler
- Arthas
- Java Mission Control
- Flame Graphs（火焰图）
- Tprofiler
- Btrace
- YourKit
- JProbe
- Spring Insight

# OOM 案例

## 堆溢出

### 报错信息

java.lang.OutOfMemoryError: Java heap space

### 参数配置

```java
-XX:+PrintGCDetails -XX:MetaspaceSize=64m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap/heapdump.hprof -XX:+PrintGCDateStamps -Xms200M -Xmx200M -Xloggc:log/gc-oomHeap.log
```



### 原因及解决

**原因**

 1、代码中可能存在大对象分配 

 2、可能存在内存泄漏，导致在多次GC之后，还是无法找到一块足够大的内存容纳当前对象。

**解决方法**

 1、检查是否存在大对象的分配，最有可能的是大数组分配 

 2、通过jmap命令，把堆内存dump下来，使用MAT等工具分析一下，检查是否存在内存泄漏的问题

 3、如果没有找到明显的内存泄漏，使用 -Xmx 加大堆内存 

 4、还有一点容易被忽略，检查是否有大量的自定义的 Finalizable 对象，也有可能是框架内部提供的，考虑其存在的必要性

分析GC日志

## 元空间溢出

> 方法区（Method Area）与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、即时编译器编译后的代码等数据。虽然Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。
>
> Java 虚拟机规范对方法区的限制非常宽松，除了和 Java 堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。垃圾收集行为在这个区域是比较少出现的，其内存回收目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。

### 报错信息

java.lang.OutOfMemoryError: Metaspace

### 参数配置

```java
-XX:+PrintGCDetails -XX:MetaspaceSize=60m -XX:MaxMetaspaceSize=60m -Xss512K -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap/heapdumpMeta.hprof -XX:SurvivorRatio=8 -XX:+TraceClassLoading -XX:+TraceClassUnloading -XX:+PrintGCDateStamps -Xms60M -Xmx60M -Xloggc:log/gc-oomMeta.log
```

### 原因及其解决

JDK8后，元空间替换了永久代，元空间使用的是本地内存

原因：

1. 运行期间生成了大量的代理类，导致方法区被撑爆，无法卸载

2. 应用长时间运行，没有重启

3. 元空间内存设置过小

解决方法：

因为该 OOM 原因比较简单，解决方法有如下几种：

1. 检查是否永久代空间或者元空间设置的过小

2. 检查代码中是否存在大量的反射操作

3. dump之后通过mat检查是否存在大量由于反射生成的代理类

## GC overhead limit exceeded

系统在频繁性的做FULL GC，但是却没有回收掉多少空间，那么引起的原因可能是因为内存不足，也可能是存在内存泄漏的情况

## 线程溢出

### 报错信息

java.lang.OutOfMemoryError : unable to create new native Thread

### 原因及其解决

出现这种异常，基本上都是创建了大量的线程导致的

解决：

1. > - 通过 -Xss 设置每个线程栈大小的容量
   >
   > - JDK5.0以后每个线程堆栈大小为1M,以前每个线程堆栈大小为256K。
   >
   > - 正常情况下，在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的,不能无限生成,经验值在3000~5000左右。
   >
   > - 能创建的线程数的具体计算公式如下：
   >
   > (MaxProcessMemory - JVMMemory - ReservedOsMemory) / (ThreadStackSize) = Number of threads
   >
   > ——————————————————————————————————————
   >
   > MaxProcessMemory 指的是进程可寻址的最大空间
   >
   > JVMMemory   JVM内存
   >
   > ReservedOsMemory 保留的操作系统内存
   >
   > ThreadStackSize  线程栈的大小
   >
   > ——————————————————————————————————————
   >
   > - 在Java语言里， 当你创建一个线程的时候，虚拟机会在JVM内存创建一个Thread对象同时创建一个操作系统线程，而这个系统线程的内存用的不是JVMMemory，而是系统中剩下的内存(MaxProcessMemory - JVMMemory - ReservedOsMemory)。
   >
   > - 由公式得出结论：**你给JVM内存越多，那么你能创建的线程越少，越容易发生java.lang.OutOfMemoryError: unable to create new native thread**
   >
   > **综上，在生产环境下如果需要更多的线程数量，建议使用64位操作系统，如果必须使用32位操作系统，可以通过调整Xss的大小来控制线程数量。**

2. > 线程总数也受到系统空闲内存和操作系统的限制，检查是否该系统下有此限制：
   >
   > - /proc/sys/kernel/pid_max      系统最大pid值，在大型系统里可适当调大
   >
   > - /proc/sys/kernel/threads-max   系统允许的最大线程数
   >
   > - maxuserprocess（ulimit -u）  系统限制某用户下最多可以运行多少进程或线程
   >
   > - /proc/sys/vm/max_map_count   
   >
   > max_map_count文件包含限制一个进程可以拥有的VMA(虚拟内存区域)的数量。虚拟内存区域是一个连续的虚拟地址空间区域。在进程的生命周期中，每当程序尝试在内存中映射文件，链接到共享内存段，或者分配堆空间的时候，这些区域将被创建。调优这个值将限制进程可拥有VMA的数量。限制一个进程拥有VMA的总数可能导致应用程序出错，因为当进程达到了VMA上线但又只能释放少量的内存给其他的内核进程使用时，操作系统会抛出内存不足的错误。如果你的操作系统在NORMAL区域仅占用少量的内存，那么调低这个值可以帮助释放内存给内核用。

# 调优的基本问题

## 为什么要调优

- 防止出现OOM，进行JVM规划和预调优
- 解决程序运行中各种OOM
- 减少Full GC出现的频率，解决运行慢、卡顿问题

## 调优的大方向

- 合理地编写代码
- 充分并合理的使用硬件资源
- 合理地进行JVM调优

## 不同阶段的考虑

- 上线前
- 项目运行阶段
- 线上出现OOM

> - 调优，从业务场景开始，没有业务场景的调优都是耍流氓！
> - 无监控，不调优！

# 调优监控的依据

- 运行日志
- 异常堆栈
- GC日志
- 线程快照
- 堆转储快照

# 性能优化的步骤

## 第1步：熟悉业务场景

## 第2步（发现问题）：性能监控

- GC 频繁
- cpu load过高
- OOM
- 内存泄漏
- 死锁
- 程序响应时间较长

## 第3步（排查问题）：性能分析

- 打印GC日志，通过GCviewer或者 http://gceasy.io来分析日志信息
- 灵活运用 命令行工具，jstack，jmap，jinfo等
- dump出堆文件，使用内存分析工具分析文件
- 使用阿里Arthas，或jconsole，JVisualVM来实时查看JVM状态
- jstack查看堆栈信息

## 第4步（解决问题）：性能调优

- 适当增加内存，根据业务背景选择垃圾回收器
- 优化代码，控制内存使用
- 增加机器，分散节点压力
- 合理设置线程池线程数量
- 使用中间件提高程序效率，比如缓存，消息队列等

# 性能评价/测试指标

- 停顿时间（或响应时间）
- 吞吐量
- 并发数
- 内存占用
- 相互间的关系

# 案例

## 案例1 - 调整堆大小提高服务吞吐量

### 修改tomcat的配置

`setenv.sh`

```shell
export CATALINA_OPTS="$CATALINA_OPTS -Xms30m"
export CATALINA_OPTS="$CATALINA_OPTS -XX:SurvivorRatio=8"
export CATALINA_OPTS="$CATALINA_OPTS -Xmx30m"
export CATALINA_OPTS="$CATALINA_OPTS -XX:+UseParallelGC"
export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDetails"
export CATALINA_OPTS="$CATALINA_OPTS -XX:MetaspaceSize=64m"
export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDateStamps"
export CATALINA_OPTS="$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc.log"
```

### JMeter测试

![image-20230514153615938](https://nq-bucket.oss-cn-shanghai.aliyuncs.com/note_img/image-20230514153615938.png)

![image-20230514152928141](https://nq-bucket.oss-cn-shanghai.aliyuncs.com/note_img/image-20230514152928141.png)

### 修改参数，重启tomcat

```shell
export CATALINA_OPTS="$CATALINA_OPTS -Xms120m"
export CATALINA_OPTS="$CATALINA_OPTS -XX:SurvivorRatio=8"
export CATALINA_OPTS="$CATALINA_OPTS -Xmx120m"
export CATALINA_OPTS="$CATALINA_OPTS -XX:+UseParallelGC"
export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDetails"
export CATALINA_OPTS="$CATALINA_OPTS -XX:MetaspaceSize=64m"
export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDateStamps"
export CATALINA_OPTS="$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc.log"
```

### 再次测试结果

![image-20230514153752816](https://nq-bucket.oss-cn-shanghai.aliyuncs.com/note_img/image-20230514153752816.png)

![image-20230514153825096](https://nq-bucket.oss-cn-shanghai.aliyuncs.com/note_img/image-20230514153825096.png)

## 案例2 - JVM优化之JIT优化

### 栈是空间分配的唯一选择吗？

> 在《深入理解Java虚拟机中》关于Java堆内存有这样一段描述：
>
> 随着JIT编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。
>
> 在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析(Escape Analysis)后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。
>
> 此外，前面提到的基于OpenJDK深度定制的TaoBaoVM，其中创新的GCIH（GC invisible heap）实现off-heap，将生命周期较长的Java对象从heap中移至heap外，并且GC不能管理GCIH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率的目的。

### 编译的开销

#### 时间开销

> 编译的时间开销：
>
> 解释器的执行，抽象的看是这样的:
>
> 输入的代码 -> [ 解释器 解释执行 ] -> 执行结果
>
> JIT编译然后再执行的话，抽象的看则是:
>
> 输入的代码 -> [ 编译器 编译 ] -> 编译后的代码 -> [ 执行 ] -> 执行结果
>
> 注意：
>
> 说JIT比解释快，其实说的是“执行编译后的代码”比“解释器解释执行”要快，并不是说“编译”这个动作比“解释”这个动作快。JIT编译再怎么快，至少也比解释执行一次略慢一些，而要得到最后的执行结果还得再经过一个“执行编译后的代码”的过程。所以，对“只执行一次”的代码而言，解释执行其实总是比JIT编译执行要快。怎么算是`只执行一次的代码`呢？粗略说，下面条件同时满足时就是严格的`只执行一次。
>
> - 只被调用一次，例如类的构造器（class initializer，()）
>
> - 没有循环，对只执行一次的代码做JIT编译再执行，可以说是得不偿失。
>
> - 对只执行少量次数的代码，JIT编译带来的执行速度的提升也未必能抵消掉最初编译带来的开销。
>
> **只有对频繁执行的代码（热点代码），JIT编译才能保证有正面的收益。**

#### 空间开销

> 对一般的Java方法而言，编译后代码的大小相对于字节码的大小，膨胀比达到10+是很正常的。同上面说时间开销一样，这里的空间开销也是，只有对执行频繁的代码才值得编译，如果把所有代码都编译则会显著增加代码所占空间，导致代码爆炸。这也就解释了为什么有些JVM会选择不总是做JIT编译，而是选择用解释器+JIT编译器的混合执行引擎。

### 逃逸分析

逃逸是指对象引用是否只在本方法内使用

#### 代码举例

```java
/**
 * 逃逸分析
 *
 *  如何快速的判断是否发生了逃逸分析，大家就看new的对象实体是否有可能在方法外被调用。
 */
public class EscapeAnalysis {

    public EscapeAnalysis obj;

    /*
    方法返回EscapeAnalysis对象，发生逃逸
     */
    public EscapeAnalysis getInstance(){
        return obj == null? new EscapeAnalysis() : obj;
    }
    /*
    为成员属性赋值，发生逃逸
     */
    public void setObj(){
        this.obj = new EscapeAnalysis();
    }
    //思考：如果当前的obj引用声明为static的，会发生逃逸吗？会！

    /*
    对象的作用域仅在当前方法中有效，没有发生逃逸
     */
    public void useEscapeAnalysis(){
        EscapeAnalysis e = new EscapeAnalysis();
    }
    /*
    引用成员变量的值，发生逃逸
     */
    public void useEscapeAnalysis1(){
        EscapeAnalysis e = getInstance();
        //getInstance().xxx()同样会发生逃逸
    }
    /*
    * 也发生了逃逸
    * */
    public void operate(EscapeAnalysis e){
        // e
    }
}

```

### 优化

#### 栈上分配

定义：将堆分配改为栈分配。需要在堆上分配内存，也无需进行垃圾回收。可以减少垃圾回收时间和次数。

**JIT编译器在编译期间根据逃逸分析的结果，发现一个对象并没有逃逸出一个方法的话，就可能被优化上栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间回收，局部变量对象也被回收。无需进行垃圾回收**

```java
/**
 * 栈上分配测试
 * -Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails
 *
 * 只要开启了逃逸分析，就会判断方法中的变量是否发生了逃逸。如果没有发生了逃逸，则会使用栈上分配
 *
 */
public class StackAllocation {
    public static void main(String[] args) {
        long start = System.currentTimeMillis();

        for (int i = 0; i < 10000000; i++) {
            alloc();
        }
        // 查看执行时间
        long end = System.currentTimeMillis();
        System.out.println("花费的时间为： " + (end - start) + " ms");
        // 为了方便查看堆内存中对象个数，线程sleep
        try {
            Thread.sleep(1000000);
        } catch (InterruptedException e1) {
            e1.printStackTrace();
        }
    }

    private static void alloc() {
        User user = new User();//是否发生逃逸？ 没有！
    }

    static class User {

    }
}

// 启用栈上分配，默认开启： -Xmx1G -Xms1G -XX:+DoEscapeAnalysis -XX:+PrintGCDetails
// 查看是否开启： jinfo -flag DoEscapeAnalysis 29500
```

##### 参数设置

- 在JDK 6u23版本之后，HotSpot中默认就已经开启了逃逸分析。
- 如果使用的是较早的版本，开发人员则可以通过：
- 通过选项“-XX:+DoEscapeAnalysis”显式开启逃逸分析
- 通过选项“-XX：+PrintEscapeAnalysis”查看逃逸分析的筛选结果。

结论：

**开发中能使用局部变量的，就不要使用在方法外定义。**

#### 同步消除（省略）

**如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步**

- 线程同步的代价是相当高的，同步的后果是降低并发性和性能。
- 在动态编译同步块的时候，**JIT编译器**可以借助逃逸分析来**判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程**。如果没有，那么JIT编译器在编译这个同步块的时候就会取消对这部分代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫同步省略，也叫**锁消除。**

```java
/**
 * 同步省略
 */
public class SynchronizedTest {
    public void f() {
        /*
        * 代码中对hollis这个对象进行加锁，但是hollis对象的生命周期只在f()方法中，
        * 并不会被其他线程所访问到，所以在JIT编译阶段就会被优化掉。
        *
        * 问题：字节码文件中会去掉hollis吗？
        * */
        Object hollis = new Object();
        synchronized(hollis) {
            System.out.println(hollis);
        }

        /*
        * 优化后；
        * Object hollis = new Object();
        * System.out.println(hollis);
        * */
    }
}

```

#### 标量替换

标量(Scalar) : 是指无法在分解成更小数据的数据。Java的原始数据类型就是标量

聚合量(Aggregate): 可以分解的数据，Java的对象就是聚合量。因为其可以分配成其它聚合量和标量。

标量替换：在JIT阶段，如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆解成若干个其中包含的若干个成员变量来代替，这个过程被称为"标量替换"

```java
/**
 * 标量替换测试
 *  -Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGCDetails -XX:-EliminateAllocations
 * 对于EliminateAllocations的开启一定要保证DoEscapeAnalysis的开启，否则是没有意义的
 *  结论：Java中的逃逸分析，其实优化的点就在于对栈上分配的对象进行标量替换。
 */
public class ScalarReplace {
    public static class User {
        public int id;
        public String name;
    }

    public static void alloc() {
        User u = new User();//未发生逃逸
        u.id = 5;
        u.name = "www.atguigu.com";
    }

    public static void main(String[] args) {
        long start = System.currentTimeMillis();
        for (int i = 0; i < 10000000; i++) {
            alloc();
        }
        long end = System.currentTimeMillis();
        System.out.println("花费的时间为： " + (end - start) + " ms");

    }
}
```



### 逃逸分析小结

> 逃逸分析小结：逃逸分析并不成熟
>
> - 关于逃逸分析的论文在1999年就已经发表了，但直到JDK 1.6才有实现，而且这项技术到如今也并不是十分成熟的。
> - 其根本原因就是无**法保证非逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。**
> - 一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。
> - 虽然这项技术并不十分成熟，但是它**也是即时编译器优化技术中一个十分重要的手段。**
> - 注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JVM设计者的选择。
> - 目前很多书籍还是基于JDK 7以前的版本，JDK已经发生了很大变化，intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：**对象实例都是分配在堆上。**

## 案例3 - 合理分配堆内存

依据的原则是根据Java Performance里面的推荐公式来进行设置。

![img](https://nq-bucket.oss-cn-shanghai.aliyuncs.com/note_img/B8309F9D-4C24-4C9A-B4F4-D5FF5CB7A0B2.png)

**Java**整个堆大小设置，Xmx 和 Xms设置为老年代存活对象的3-4倍，即FullGC之后的老年代内存占用的3-4倍。 方法区（永久代 PermSize和MaxPermSize 或 元空间 MetaspaceSize 和 MaxMetaspaceSize）设置为老年代存活对象的1.2-1.5倍。 年轻代Xmn的设置为老年代存活对象的1-1.5倍。 老年代的内存大小设置为老年代存活对象的2-3倍。

但是，上面的说法也不是绝对的，也就是说这给的是一个参考值，根据多种调优之后得出的一个结论，大家可以根据这个值来设置一下我们的初始化内存，在保证程序正常运行的情况下，我们还要去查看GC的回收率，GC停顿耗时，内存里的实际数据来判断，Full GC是基本上不能有的，如果有就要做内存Dump分析，然后再去做一个合理的内存分配。

### 如何计算老年代存活对象

#### 方式1 - 查看日志

推荐的方法

JVM参数中添加GC日志，GC日志中会记录每次FullGC之后各代的内存大小，观察老年代GC之后的空间大小。可观察一段时间内（比如2天）的FullGC之后的内存情况，根据多次的FullGC之后的老年代的空间大小数据来预估FullGC之后老年代的存活对象大小（可根据多次FullGC之后的内存大小取平均值）。

#### 方式2 - 强制触发

影响线上服务，谨慎使用

强制触发FullGC，会造成线上服务停顿（STW），要谨慎！建议的操作方式为，**在强制FullGC前先把服务节点摘除，FullGC之后再将服务挂回可用节点，对外提供服务，在不同时间段触发FullGC，根据多次FullGC之后的老年代内存情况来预估FullGC之后的老年代存活对象大小。**

1. jmap -dump:live,format=b,file=heap.bin 将当前的存活对象dump到文件，此时会触发FullGC
2. jmap -histo:live 打印每个class的实例数目,内存占用,类全名信息.live子参数加上后,只统计活的对象数量. 此时会触发FullGC
3. 在性能测试环境，可以通过Java监控工具来触发FullGC，比如使用VisualVM和JConsole，VisualVM集成了JConsole，VisualVM或者JConsole上面有一个触发GC的按钮。

### 配置参数

```java
JVM设置如下：
-XX:+PrintGCDetails -XX:MetaspaceSize=64m -Xss512K -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap/heapdump3.hprof  -XX:SurvivorRatio=8  -XX:+PrintGCDateStamps  -Xms1024M  -Xmx1024M -Xloggc:log/gc-oom3.log
```

### 结论

在内存相对紧张的情况下，可以按照上述的方式来进行内存的调优， 找到一个在GC频率和GC耗时上都可接受的一个内存设置，可**以用较小的内存满足当前的服务需要。**

**但当内存相对宽裕的时候，可以相对给服务多增加一点内存，可以减少GC的频率**，GC的耗时相应会增加一些。 一般要求低延时的可以考虑多设置一点内存， 对延时要求不高的，可以按照上述方式设置较小内存。 

如果在垃圾回收日志中观察到OutOfMemoryError,尝试把Java堆的大小扩大到物理内存的80%~90%。尤其需要注意的是堆空间导致的OutOfMemoryError以及一定要增加空间。

- 比如说，增加-Xms和-Xmx的值来解决old代的OutOfMemoryError

- 增加-XX:PermSize和-XX:MaxPermSize来解决permanent代引起的OutOfMemoryError（jdk7之前）；增加-XX:MetaspaceSize和-XX:MaxMetaspaceSize来解决Metaspace引起的OutOfMemoryError（jdk8之后）

**记住一点Java堆能够使用的容量受限于硬件以及是否使用64位的JVM。在扩大了Java堆的大小之后，再检查垃圾回收日志，直到没有OutOfMemoryError为止。如果应用运行在稳定状态下没有OutOfMemoryError就可以进入下一步了，计算活动对象的大小。**

### 估算GC频率

> 正常情况我们应该根据我们的系统来进行一个内存的估算，这个我们可以在测试环境进行测试，最开始可以将内存设置的大一些，比如4G这样，当然这也可以根据业务系统估算来的。
>
> 比如从数据库获取一条数据占用128个字节，需要获取1000条数据，那么一次读取到内存的大小就是（128 B/1024 Kb/1024M）* 1000 = 0.122M ，那么我们程序可能需要并发读取，比如每秒读取100次，那么内存占用就是0.122*100 = 12.2M ，如果堆内存设置1个G，那么年轻代大小大约就是333M，那么333M*80% / 12.2M =21.84s ，也就是说我们的程序几乎每分钟进行两到三次youngGC。这样可以让我们对系统有一个大致的估算。
>
> 0.122M * 100 = 12.2M /秒 ---Eden区
>
> 1024M * 1/3 * 80% = 273M 
>
> 273 / 12.2M = 22.38s ---> YGC 每分钟2-3次YGC 

## 特殊问题：自适应调整策略

### 现象设置

```java
/**
 * 使用ParallelGC的情况下，不管是否开启了UseAdaptiveSizePolicy参数，默认Eden与Survivor的比例都为：6:1:1
 * 
 * 第一次运行设置: -XX:+PrintGCDetails   -XX:+PrintGCDateStamps  -Xms300M  -Xmx300M -Xloggc:log/gc.log
 jps -l
 jmap -heap jpsId
 SurvivorRatio是8:1:1
 可是实际计算是6:1:1
 *
 * @author shkstart
 * @create 12:53
 */
public class AdaptiveSizePolicyTest {
    public static void main(String[] args) {
        try {
            Thread.sleep(1000000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

### 参数AdaptiveSizePolicy

JDK1.8默认使用了UseParallelGC 垃圾回收器，该垃圾回收器默认启动了 AdaptiveSizePolicy，会根据GC的情况自动计算Eden,From和To区的大小。所以这是由于JDK1.8的自适应大小策略导致的。

开启：-XX:+UseAdaptiveSizePolicy

关闭：-XX:-UseAdaptiveSizePolicy

#### 注意事项

1. 在 JDK 1.8 中，如果使用 CMS，无论 UseAdaptiveSizePolicy 如何设置，都会将 UseAdaptiveSizePolicy 设置为 false；不过不同版本的JDK存在差异。
2. **UseAdaptiveSizePolicy不要和SurvivorRatio参数显示设置搭配使用，一起使用会导致参数失效；**

3. 由于UseAdaptiveSizePolicy会动态调整 Eden、Survivor 的大小，有些情况存在Survivor 被自动调为很小，比如十几MB甚至几MB的可能，这个时候YGC回收掉 Eden区后，还存活的对象进入Survivor 装不下，就会直接晋升到老年代，导致老年代占用空间逐渐增加，从而触发FULL GC，如果一次FULL GC的耗时很长（比如到达几百毫秒），那么在要求高响应的系统就是不可取的。**对于面向外部的大流量、低延迟系统，不建议启用此参数，建议关闭该参数。**

如果不想动态调整内存大小，以下是解决方案：

1. 保持使用 UseParallelGC，显式设置 -XX:SurvivorRatio=8
2. 使用 CMS 垃圾回收器。CMS 默认关闭 AdaptiveSizePolicy。配置参数 -XX:+UseConcMarkSweepGC

#### 补充

关于堆内存的自适应调节有如下三个参数：调整堆是按照每次20%增长，按照每次5%收缩

young区增长量（默认20%）：-XX:YoungGenerationSizeIncrement=

old区增长量（默认20%）：-XX:TenuredGenerationSizeIncrement=

收缩量（默认5%）：-XX:AdaptiveSizeDecrementScaleFactor=

## 案例4 - CPU占用很高排查方案

### 案例复习

```java
/**
 * <pre>
 *    @author  : shkstart
 *    desc    : jstack 死锁案例
 * </pre>
 */
public class JstackDeadLockDemo {
    /**
     * 必须有两个可以被加锁的对象才能产生死锁，只有一个不会产生死锁问题
     */
    private final Object obj1 = new Object();
    private final Object obj2 = new Object();

    public static void main(String[] args) {
        new JstackDeadLockDemo().testDeadlock();
    }

    private void testDeadlock() {
        Thread t1 = new Thread(() -> calLock_Obj1_First());
        Thread t2 = new Thread(() -> calLock_Obj2_First());
        t1.start();
        t2.start();
    }

    /**
     * 先synchronized  obj1，再synchronized  obj2
     */
    private void calLock_Obj1_First() {
        synchronized (obj1) {
            sleep();
            System.out.println("已经拿到obj1的对象锁，接下来等待obj2的对象锁");
            synchronized (obj2) {
                sleep();
            }
        }
    }

    /**
     * 先synchronized  obj2，再synchronized  obj1
     */
    private void calLock_Obj2_First() {
        synchronized (obj2) {
            sleep();
            System.out.println("已经拿到obj2的对象锁，接下来等待obj1的对象锁");
            synchronized (obj1) {
                sleep();
            }
        }
    }

    /**
     * 为了便于让两个线程分别锁住其中一个对象，
     * 一个线程锁住obj1，然后一直等待obj2，
     * 另一个线程锁住obj2，然后一直等待obj1，
     * 然后就是一直等待，死锁产生
     */
    private void sleep() {
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```



### 排查方案

1. 查看java进程ID, `jps -l` # 31695 
2. 根据进行进程ID, 查看异常线程ID, `top -Hp 31695 `
3. 把线程pid变为16进制如 31695 -> 7bcf 然后得到0x7bcf
4. jstack 1456 > jstack.log  得到相关进程的代码 (鉴于我们当前代码量比较小，线程也比较少，所以我们就把所有的信息全部导出来)
5. 打开jstack.log文件，查找一下刚刚我们转换完的16进制ID是否存在
6. jstack命令生成的thread dump信息包含了JVM中所有存活的线程，里面确实是存在我们定位到的线程 ID ，在thread dump中每个线程都有一个nid，在nid=0x5b9的线程调用栈中，我们发现两个线程在互相等待对方释放资源

### 解决方案

1. 调整锁的顺序，保持一致
2. 或者采用定时锁，一段时间后，如果还不能获取到锁就释放自身持有的所有锁。

## 案例5 - G1并发执行的线程数对性能的影响

### 配置信息

硬件配置 8核linux

> export CATALINA_OPTS="$CATALINA_OPTS -XX:+UseG1GC"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xms30m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xmx30m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDetails"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:MetaspaceSize=64m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDateStamps"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc.log"
>
> **export CATALINA_OPTS="$CATALINA_OPTS -XX:ConcGCThreads=1"**
>
> **说明：最后一个参数可以在使用G1GC测试初始并发GCThreads之后再加上。**
>
> 初始化内存和最大内存调整小一些，目的发生 FullGC，关注GC时间
>
> 关注点是：GC次数，GC时间，以及 Jmeter的平均响应时间

### 总结

配置完线程数之后，请求的平均响应时间和GC时间都有一个明显的减少了，仅从效果上来看，我们这次的优化是有一定效果的。大家在工作中对于线上项目进行优化的时候，可以考虑到这方面的优化。

## 案例6 - 调整垃圾回收器提高服务的吞吐量

### 初始配置

系统配置是单核，显示DefNew，说明我们用的是串行收集器，SerialGC

### 优化配置1

使用并行垃圾收集器

> export CATALINA_OPTS="$CATALINA_OPTS -Xms60m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xmx60m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:+UseParallelGC"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDetails"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:MetaspaceSize=64m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDateStamps"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc6.log"

**查看吞吐量，997.6/sec，吞吐量并没有明显变化，究其原因，本身UseParallelGC是并行收集器，但是我们的服务器是单核。**

### 修改配置

把服务器改为8核

### 优化配置2

> export CATALINA_OPTS="$CATALINA_OPTS -XX:+UseG1GC"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xms60m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xmx60m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDetails"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:MetaspaceSize=64m"
>
> export CATALINA_OPTS="$CATALINA_OPTS -XX:+PrintGCDateStamps"
>
> export CATALINA_OPTS="$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc6.log"

**吞吐量也是比串行收集器效果更佳，而且没有了FullGC。此次优化成功**

## 案例7 - 日均百万级订单交易系统如何设置JVM参数

1. 首先估算每秒产生对象例如2M
2. 触发MinorGc的时间

**解决措施：**

1. 水平扩容更多的机器，控制每台jvm处理的请求
2. 提高新生代，降低GC频率，减少fullGC

多次的FULLGC，对系统影响性能较大。

# 面试小结

## 12306遭遇春节大规模抢票如何支撑？

> 12306号称是国内并发量最大的秒杀网站，并发量达到百万级别。
>
> 普通电商订单--> 下单 --> 订单系统（IO）减库存 ---> 等待用户付款
>
> 12306一种可能的模型：下单 --> 减库存和订单（redis、kafka）同时异步进行 --> 等付款
>
> 但减库存最后还会把压力压到一台服务器上。如何？

解决措施： **分布式本地库存+单独服务器做库存均衡**

## 有一个50万PV的资料类网站（从磁盘提取文档到内存）原服务器是32位的，1.5G的堆，用户反馈网站比较缓慢。因此公司决定升级，新的服务器为64位，16G的堆内存，结果用户反馈卡顿十分严重，反而比以前效率更低了！

1. 为什么原网站慢？
   **频繁的GC,STW时间比较长，响应时间慢！**
2.  为什么会更卡顿？
   **内存空间越大，FGC时间更长，延迟时间更长**
3. 解决措施
   - 垃圾回收器
     - parallel GC 
     - ParNew + CMS
     -  G1
   - 配置GC参数： -XX:MaxGCPauseMillis 、 -XX:ConcGCThreads 
   - 根据log日志、dump文件分析，优化内存空间的比例： jstat  jinfo jstack jmap 

## 系统CPU经常100%，如何调优？

CPU100%的话，一定是有线程占用系统资源。分析进程线程

## 系统内存飙高，如何查找问题？

1. jmap -heap 、jstat 、... ; gc日志情况
2. dump文件分析

## 如何监控JVM

- 命令行工具
- 图形化界面工具
